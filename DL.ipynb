{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3aKx2uft9SUoYFMaAK9Hs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/223t1a3127/Sree/blob/main/DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqiv5k8e629B",
        "outputId": "1f523b1d-64f7-4dda-8a2e-cb42e42704c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "189/189 [==============================] - 3s 6ms/step - loss: 6835.9536 - val_loss: 918.8851\n",
            "Epoch 2/5\n",
            "189/189 [==============================] - 1s 5ms/step - loss: 300.3220 - val_loss: 135.8162\n",
            "Epoch 3/5\n",
            "189/189 [==============================] - 1s 5ms/step - loss: 77.0636 - val_loss: 34.7950\n",
            "Epoch 4/5\n",
            "189/189 [==============================] - 1s 5ms/step - loss: 18.3270 - val_loss: 7.1915\n",
            "Epoch 5/5\n",
            "189/189 [==============================] - 1s 5ms/step - loss: 3.7550 - val_loss: 1.7126\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 1.7538\n",
            "Test Loss: 1.7537944316864014\n",
            "1/1 [==============================] - 0s 197ms/step\n",
            "Predicted Sum: 68.8597640991211\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=34, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=4, batch_size=27, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV2-kh5M7kdZ",
        "outputId": "4e403fad-9332-4046-e5e0-b6ac20cd975e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "238/238 [==============================] - 2s 4ms/step - loss: 13939.5195 - val_loss: 11790.4062\n",
            "Epoch 2/4\n",
            "238/238 [==============================] - 2s 8ms/step - loss: 11695.9961 - val_loss: 11438.5664\n",
            "Epoch 3/4\n",
            "238/238 [==============================] - 2s 10ms/step - loss: 11488.5391 - val_loss: 11325.2510\n",
            "Epoch 4/4\n",
            "238/238 [==============================] - 1s 4ms/step - loss: 11402.4297 - val_loss: 11255.7324\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 11023.4453\n",
            "Test Loss: 11023.4453125\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "Predicted Sum: 0.9111872315406799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=6, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv1GvyW17v-n",
        "outputId": "7dadcd2f-a3a4-48db-c9c8-bc7934341054"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 12259.4258 - val_loss: 9913.7695\n",
            "Epoch 2/6\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 7637.3457 - val_loss: 5619.9233\n",
            "Epoch 3/6\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 3403.9431 - val_loss: 1557.3969\n",
            "Epoch 4/6\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 593.5206 - val_loss: 118.1211\n",
            "Epoch 5/6\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 55.2607 - val_loss: 34.3935\n",
            "Epoch 6/6\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 27.5777 - val_loss: 18.7078\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 18.8094\n",
            "Test Loss: 18.809404373168945\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Predicted Sum: 65.61483764648438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=7, batch_size=38, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWps4zVA74H4",
        "outputId": "8f22d6ad-70f0-47db-8f64-d21302821a11"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "169/169 [==============================] - 2s 3ms/step - loss: 5697.6118 - val_loss: 1165.7488\n",
            "Epoch 2/7\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 270.6540 - val_loss: 72.0222\n",
            "Epoch 3/7\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 39.7348 - val_loss: 19.4883\n",
            "Epoch 4/7\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 9.4200 - val_loss: 4.9124\n",
            "Epoch 5/7\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 2.9948 - val_loss: 2.5263\n",
            "Epoch 6/7\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 1.9741 - val_loss: 1.9243\n",
            "Epoch 7/7\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 1.5621 - val_loss: 1.5216\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.3761\n",
            "Test Loss: 1.376055121421814\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "Predicted Sum: 68.40560150146484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=8, batch_size=42, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtZz_Anq8Axs",
        "outputId": "3ff23c1b-92d4-4131-d4d8-4d516a55242f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "153/153 [==============================] - 1s 4ms/step - loss: 4877.6743 - val_loss: 778.8535\n",
            "Epoch 2/8\n",
            "153/153 [==============================] - 1s 4ms/step - loss: 106.5588 - val_loss: 4.1493\n",
            "Epoch 3/8\n",
            "153/153 [==============================] - 1s 8ms/step - loss: 3.5027 - val_loss: 3.1649\n",
            "Epoch 4/8\n",
            "153/153 [==============================] - 0s 3ms/step - loss: 2.6306 - val_loss: 1.5580\n",
            "Epoch 5/8\n",
            "153/153 [==============================] - 0s 3ms/step - loss: 0.7703 - val_loss: 0.5134\n",
            "Epoch 6/8\n",
            "153/153 [==============================] - 0s 3ms/step - loss: 0.4724 - val_loss: 0.4142\n",
            "Epoch 7/8\n",
            "153/153 [==============================] - 0s 2ms/step - loss: 0.4025 - val_loss: 0.3659\n",
            "Epoch 8/8\n",
            "153/153 [==============================] - 0s 3ms/step - loss: 0.3554 - val_loss: 0.3235\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3435\n",
            "Test Loss: 0.3435131013393402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x788454873eb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n",
            "Predicted Sum: 69.00515747070312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=9, batch_size=44, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJVPlJo98HZe",
        "outputId": "0e0a2000-c175-440c-ba11-1de1079a6f0f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "146/146 [==============================] - 1s 4ms/step - loss: 14320.9062 - val_loss: 11367.3037\n",
            "Epoch 2/9\n",
            "146/146 [==============================] - 0s 2ms/step - loss: 9721.3672 - val_loss: 5867.0552\n",
            "Epoch 3/9\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 1947.8707 - val_loss: 158.0121\n",
            "Epoch 4/9\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 76.6292 - val_loss: 40.5531\n",
            "Epoch 5/9\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 25.1919 - val_loss: 16.9960\n",
            "Epoch 6/9\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 11.4802 - val_loss: 7.8928\n",
            "Epoch 7/9\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 5.7515 - val_loss: 4.3932\n",
            "Epoch 8/9\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 3.3850 - val_loss: 2.6905\n",
            "Epoch 9/9\n",
            "146/146 [==============================] - 0s 3ms/step - loss: 2.0990 - val_loss: 1.6046\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.5829\n",
            "Test Loss: 1.5828900337219238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x788451f9f9a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 85ms/step\n",
            "Predicted Sum: 69.98999786376953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=48, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bBIyBSO8Yik",
        "outputId": "065f4830-13b5-4616-b6e9-98f253b682e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 10552.1777 - val_loss: 7445.2383\n",
            "Epoch 2/10\n",
            "134/134 [==============================] - 0s 3ms/step - loss: 3001.0657 - val_loss: 768.0427\n",
            "Epoch 3/10\n",
            "134/134 [==============================] - 0s 3ms/step - loss: 335.2073 - val_loss: 88.9146\n",
            "Epoch 4/10\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 39.8665 - val_loss: 16.9626\n",
            "Epoch 5/10\n",
            "134/134 [==============================] - 0s 3ms/step - loss: 12.3279 - val_loss: 9.4351\n",
            "Epoch 6/10\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.8257 - val_loss: 6.5851\n",
            "Epoch 7/10\n",
            "134/134 [==============================] - 0s 3ms/step - loss: 5.5193 - val_loss: 4.6197\n",
            "Epoch 8/10\n",
            "134/134 [==============================] - 0s 4ms/step - loss: 3.8898 - val_loss: 3.3921\n",
            "Epoch 9/10\n",
            "134/134 [==============================] - 1s 5ms/step - loss: 3.1670 - val_loss: 2.9809\n",
            "Epoch 10/10\n",
            "134/134 [==============================] - 1s 5ms/step - loss: 2.8108 - val_loss: 2.6721\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 2.5909\n",
            "Test Loss: 2.590883731842041\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "Predicted Sum: 68.1484146118164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=12, batch_size=55, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5EvFtrK8ge5",
        "outputId": "554230da-06fc-4e89-dfc4-144f584483d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "117/117 [==============================] - 2s 4ms/step - loss: 2746.7129 - val_loss: 334.9671\n",
            "Epoch 2/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 182.3559 - val_loss: 91.9189\n",
            "Epoch 3/12\n",
            "117/117 [==============================] - 1s 7ms/step - loss: 43.8769 - val_loss: 16.0633\n",
            "Epoch 4/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 7.2407 - val_loss: 2.6898\n",
            "Epoch 5/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.9854 - val_loss: 1.4343\n",
            "Epoch 6/12\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 1.2957 - val_loss: 1.0777\n",
            "Epoch 7/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.9767 - val_loss: 0.8250\n",
            "Epoch 8/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.7512 - val_loss: 0.6356\n",
            "Epoch 9/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.4996\n",
            "Epoch 10/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4652 - val_loss: 0.3993\n",
            "Epoch 11/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.3753 - val_loss: 0.3268\n",
            "Epoch 12/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.3077 - val_loss: 0.2691\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.2737\n",
            "Test Loss: 0.2736956477165222\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "Predicted Sum: 68.36856842041016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=14, batch_size=60, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcQRij5O8zpT",
        "outputId": "84584f3e-b9a7-445a-fbcb-f17eb45014ba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "107/107 [==============================] - 1s 4ms/step - loss: 5077.0449 - val_loss: 2077.2415\n",
            "Epoch 2/14\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 745.5789 - val_loss: 46.5600\n",
            "Epoch 3/14\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 8.0313 - val_loss: 1.8318\n",
            "Epoch 4/14\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.7494 - val_loss: 1.5483\n",
            "Epoch 5/14\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.4618 - val_loss: 1.3297\n",
            "Epoch 6/14\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.2261 - val_loss: 1.1313\n",
            "Epoch 7/14\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 1.0286 - val_loss: 0.9534\n",
            "Epoch 8/14\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.8553 - val_loss: 0.7892\n",
            "Epoch 9/14\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.6984 - val_loss: 0.6467\n",
            "Epoch 10/14\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.5520 - val_loss: 0.5010\n",
            "Epoch 11/14\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.4305 - val_loss: 0.3903\n",
            "Epoch 12/14\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.3369 - val_loss: 0.2993\n",
            "Epoch 13/14\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.2599 - val_loss: 0.2261\n",
            "Epoch 14/14\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.1983 - val_loss: 0.1752\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.1664\n",
            "Test Loss: 0.16641850769519806\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "Predicted Sum: 68.36934661865234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=62, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W07_fgbq9L_h",
        "outputId": "9a2d1c4c-1419-4b15-a49f-0d3b99f6b692"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 13487.9297 - val_loss: 10358.8066\n",
            "Epoch 2/15\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 7288.8550 - val_loss: 3954.4807\n",
            "Epoch 3/15\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1396.3872 - val_loss: 146.9762\n",
            "Epoch 4/15\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 64.7361 - val_loss: 39.3976\n",
            "Epoch 5/15\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 27.0437 - val_loss: 17.9231\n",
            "Epoch 6/15\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 12.1516 - val_loss: 8.0118\n",
            "Epoch 7/15\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 5.7779 - val_loss: 4.1766\n",
            "Epoch 8/15\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.3964 - val_loss: 2.8181\n",
            "Epoch 9/15\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5450 - val_loss: 2.2700\n",
            "Epoch 10/15\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.0808 - val_loss: 1.8865\n",
            "Epoch 11/15\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8236 - val_loss: 1.7142\n",
            "Epoch 12/15\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.6818 - val_loss: 1.5854\n",
            "Epoch 13/15\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5550 - val_loss: 1.4570\n",
            "Epoch 14/15\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4252 - val_loss: 1.3240\n",
            "Epoch 15/15\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2886 - val_loss: 1.1837\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 1.2213\n",
            "Test Loss: 1.2213107347488403\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "Predicted Sum: 68.40157318115234\n"
          ]
        }
      ]
    }
  ]
}