{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfjI14cOAS0qUSASjm2f8D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/223t1a3127/Sree/blob/main/DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqiv5k8e629B",
        "outputId": "fe7c9d72-0939-4c41-9b60-23a61548e688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "118/118 [==============================] - 4s 7ms/step - loss: 9523.5000 - val_loss: 6772.7969\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 3815.4915 - val_loss: 1223.6609\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 374.0022 - val_loss: 41.4148\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 25.9137 - val_loss: 19.0036\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 15.8750 - val_loss: 12.3158\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 11.9160\n",
            "Test Loss: 11.916046142578125\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "Predicted Sum: 66.44482421875\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=34, validation_split=0.5)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=4, batch_size=27, validation_split=0.4)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV2-kh5M7kdZ",
        "outputId": "e910c275-9306-45fe-ecba-d8f4dfad3beb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "178/178 [==============================] - 1s 4ms/step - loss: 12388.4854 - val_loss: 11650.5459\n",
            "Epoch 2/4\n",
            "178/178 [==============================] - 1s 5ms/step - loss: 11566.8389 - val_loss: 11307.6680\n",
            "Epoch 3/4\n",
            "178/178 [==============================] - 1s 5ms/step - loss: 11415.0938 - val_loss: 11248.6328\n",
            "Epoch 4/4\n",
            "178/178 [==============================] - 1s 5ms/step - loss: 11368.4648 - val_loss: 11210.7441\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 11354.0068\n",
            "Test Loss: 11354.0068359375\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "Predicted Sum: 0.6969323754310608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=6, batch_size=64, validation_split=0.3)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv1GvyW17v-n",
        "outputId": "53b7ce72-ea20-4f12-862c-316d90fd11ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "88/88 [==============================] - 2s 5ms/step - loss: 8350.6426 - val_loss: 5474.6626\n",
            "Epoch 2/6\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 3137.6304 - val_loss: 1360.3280\n",
            "Epoch 3/6\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 635.2740 - val_loss: 315.9781\n",
            "Epoch 4/6\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 172.5191 - val_loss: 94.6494\n",
            "Epoch 5/6\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 49.5621 - val_loss: 29.5234\n",
            "Epoch 6/6\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 16.9466 - val_loss: 12.9152\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 11.7224\n",
            "Test Loss: 11.722439765930176\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "Predicted Sum: 66.61651611328125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=7, batch_size=38, validation_split=0.2)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWps4zVA74H4",
        "outputId": "8f22d6ad-70f0-47db-8f64-d21302821a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "169/169 [==============================] - 2s 3ms/step - loss: 5697.6118 - val_loss: 1165.7488\n",
            "Epoch 2/7\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 270.6540 - val_loss: 72.0222\n",
            "Epoch 3/7\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 39.7348 - val_loss: 19.4883\n",
            "Epoch 4/7\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 9.4200 - val_loss: 4.9124\n",
            "Epoch 5/7\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 2.9948 - val_loss: 2.5263\n",
            "Epoch 6/7\n",
            "169/169 [==============================] - 1s 3ms/step - loss: 1.9741 - val_loss: 1.9243\n",
            "Epoch 7/7\n",
            "169/169 [==============================] - 0s 3ms/step - loss: 1.5621 - val_loss: 1.5216\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.3761\n",
            "Test Loss: 1.376055121421814\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "Predicted Sum: 68.40560150146484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=8, batch_size=68, validation_split=0.6)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtZz_Anq8Axs",
        "outputId": "2e05f1f0-c2f6-490b-9c2f-7983a89f79e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "48/48 [==============================] - 1s 7ms/step - loss: 1630.8738 - val_loss: 546.0924\n",
            "Epoch 2/8\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 232.4167 - val_loss: 111.6060\n",
            "Epoch 3/8\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 86.2434 - val_loss: 63.6968\n",
            "Epoch 4/8\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 49.5528 - val_loss: 37.4883\n",
            "Epoch 5/8\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 32.5941 - val_loss: 26.8086\n",
            "Epoch 6/8\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 23.6666 - val_loss: 19.4154\n",
            "Epoch 7/8\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 17.2630 - val_loss: 14.1262\n",
            "Epoch 8/8\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 12.7975 - val_loss: 10.5079\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 9.8935\n",
            "Test Loss: 9.893512725830078\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Predicted Sum: 68.00930786132812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=9, batch_size=64, validation_split=0.7)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJVPlJo98HZe",
        "outputId": "7487b615-2f72-470a-f69a-d2a512b8eac4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "38/38 [==============================] - 1s 8ms/step - loss: 14574.5098 - val_loss: 12908.9424\n",
            "Epoch 2/9\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 11493.7246 - val_loss: 9808.3418\n",
            "Epoch 3/9\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 8279.5000 - val_loss: 6477.2900\n",
            "Epoch 4/9\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 4927.8540 - val_loss: 3259.1243\n",
            "Epoch 5/9\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 2093.8196 - val_loss: 1025.7382\n",
            "Epoch 6/9\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 573.2942 - val_loss: 236.2130\n",
            "Epoch 7/9\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 147.7758 - val_loss: 95.2988\n",
            "Epoch 8/9\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 80.0871 - val_loss: 72.0539\n",
            "Epoch 9/9\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 62.7909 - val_loss: 57.5163\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 53.1900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x78a2434fe440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 53.19001770019531\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Predicted Sum: 70.89004516601562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=48, validation_split=0.8)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bBIyBSO8Yik",
        "outputId": "fa289dbd-b8f9-480b-acca-8d432787330e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 1s 15ms/step - loss: 4227.3174 - val_loss: 3490.7832\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 2858.0000 - val_loss: 2191.9355\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 1671.1198 - val_loss: 1145.6895\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 799.1537 - val_loss: 473.9193\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 298.2775 - val_loss: 149.9439\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 88.9131 - val_loss: 41.5247\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 26.6680 - val_loss: 16.1280\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 12.6255 - val_loss: 10.1808\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 8.4975 - val_loss: 7.4017\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 0s 13ms/step - loss: 6.2145 - val_loss: 5.6308\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 5.5114\n",
            "Test Loss: 5.511404514312744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x78a242c253f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 112ms/step\n",
            "Predicted Sum: 69.8991928100586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=12, batch_size=55, validation_split=0.2)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5EvFtrK8ge5",
        "outputId": "554230da-06fc-4e89-dfc4-144f584483d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "117/117 [==============================] - 2s 4ms/step - loss: 2746.7129 - val_loss: 334.9671\n",
            "Epoch 2/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 182.3559 - val_loss: 91.9189\n",
            "Epoch 3/12\n",
            "117/117 [==============================] - 1s 7ms/step - loss: 43.8769 - val_loss: 16.0633\n",
            "Epoch 4/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 7.2407 - val_loss: 2.6898\n",
            "Epoch 5/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 1.9854 - val_loss: 1.4343\n",
            "Epoch 6/12\n",
            "117/117 [==============================] - 0s 4ms/step - loss: 1.2957 - val_loss: 1.0777\n",
            "Epoch 7/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.9767 - val_loss: 0.8250\n",
            "Epoch 8/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.7512 - val_loss: 0.6356\n",
            "Epoch 9/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.5849 - val_loss: 0.4996\n",
            "Epoch 10/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.4652 - val_loss: 0.3993\n",
            "Epoch 11/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.3753 - val_loss: 0.3268\n",
            "Epoch 12/12\n",
            "117/117 [==============================] - 0s 3ms/step - loss: 0.3077 - val_loss: 0.2691\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.2737\n",
            "Test Loss: 0.2736956477165222\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "Predicted Sum: 68.36856842041016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=14, batch_size=60, validation_split=0.9)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcQRij5O8zpT",
        "outputId": "a886cfd6-0839-47ea-8798-bb62214dfc6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "14/14 [==============================] - 1s 24ms/step - loss: 9005.9521 - val_loss: 8456.9414\n",
            "Epoch 2/14\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 8236.5654 - val_loss: 7656.0312\n",
            "Epoch 3/14\n",
            "14/14 [==============================] - 0s 30ms/step - loss: 7382.1426 - val_loss: 6790.8120\n",
            "Epoch 4/14\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 6466.7417 - val_loss: 5879.2808\n",
            "Epoch 5/14\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 5508.2339 - val_loss: 4929.7935\n",
            "Epoch 6/14\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 4543.1655 - val_loss: 3979.3679\n",
            "Epoch 7/14\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 3588.1270 - val_loss: 3068.1162\n",
            "Epoch 8/14\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 2698.6562 - val_loss: 2234.9241\n",
            "Epoch 9/14\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 1908.3251 - val_loss: 1517.6783\n",
            "Epoch 10/14\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 1245.7489 - val_loss: 965.5732\n",
            "Epoch 11/14\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 758.4846 - val_loss: 564.4285\n",
            "Epoch 12/14\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 423.7627 - val_loss: 315.7964\n",
            "Epoch 13/14\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 229.7643 - val_loss: 181.8081\n",
            "Epoch 14/14\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 135.5572 - val_loss: 119.4056\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 122.6296\n",
            "Test Loss: 122.62963104248047\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Predicted Sum: 70.73873901367188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=62, validation_split=0.2)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W07_fgbq9L_h",
        "outputId": "9a2d1c4c-1419-4b15-a49f-0d3b99f6b692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 13487.9297 - val_loss: 10358.8066\n",
            "Epoch 2/15\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 7288.8550 - val_loss: 3954.4807\n",
            "Epoch 3/15\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1396.3872 - val_loss: 146.9762\n",
            "Epoch 4/15\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 64.7361 - val_loss: 39.3976\n",
            "Epoch 5/15\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 27.0437 - val_loss: 17.9231\n",
            "Epoch 6/15\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 12.1516 - val_loss: 8.0118\n",
            "Epoch 7/15\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 5.7779 - val_loss: 4.1766\n",
            "Epoch 8/15\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.3964 - val_loss: 2.8181\n",
            "Epoch 9/15\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.5450 - val_loss: 2.2700\n",
            "Epoch 10/15\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.0808 - val_loss: 1.8865\n",
            "Epoch 11/15\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8236 - val_loss: 1.7142\n",
            "Epoch 12/15\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.6818 - val_loss: 1.5854\n",
            "Epoch 13/15\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5550 - val_loss: 1.4570\n",
            "Epoch 14/15\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4252 - val_loss: 1.3240\n",
            "Epoch 15/15\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2886 - val_loss: 1.1837\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 1.2213\n",
            "Test Loss: 1.2213107347488403\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "Predicted Sum: 68.40157318115234\n"
          ]
        }
      ]
    }
  ]
}